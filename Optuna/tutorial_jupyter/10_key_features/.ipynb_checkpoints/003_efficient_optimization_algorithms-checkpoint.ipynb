{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Efficient Optimization Algorithms\n",
    "\n",
    "Optuna enables efficient hyperparameter optimization by\n",
    "adopting state-of-the-art algorithms for sampling hyperparameters and\n",
    "pruning efficiently unpromising trials.\n",
    "\n",
    "## Sampling Algorithms\n",
    "\n",
    "Samplers basically continually narrow down the search space using the records of suggested parameter values and evaluated objective values,\n",
    "leading to an optimal search space which giving off parameters leading to better objective values.\n",
    "More detailed explanation of how samplers suggest parameters is in :class:`optuna.samplers.BaseSampler`.\n",
    "\n",
    "Optuna provides the following sampling algorithms:\n",
    "\n",
    "- Tree-structured Parzen Estimator algorithm implemented in :class:`optuna.samplers.TPESampler`\n",
    "\n",
    "- CMA-ES based algorithm implemented in :class:`optuna.samplers.CmaEsSampler`\n",
    "\n",
    "- Grid Search implemented in :class:`optuna.samplers.GridSampler`\n",
    "\n",
    "- Random Search implemented in :class:`optuna.samplers.RandomSampler`\n",
    "\n",
    "The default sampler is :class:`optuna.samplers.TPESampler`.\n",
    "\n",
    "## Switching Samplers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Optuna uses :class:`~optuna.samplers.TPESampler` as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:58:51,520]\u001b[0m A new study created in memory with name: no-name-ebeb9ff0-0004-4be8-98c4-dfcff29068d5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler is TPESampler\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use different samplers for example :class:`~optuna.samplers.RandomSampler`\n",
    "and :class:`~optuna.samplers.CmaEsSampler`,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:58:54,404]\u001b[0m A new study created in memory with name: no-name-6b478be8-5f17-4406-804a-ac433fe30de2\u001b[0m\n",
      "\u001b[32m[I 2022-07-05 22:58:54,406]\u001b[0m A new study created in memory with name: no-name-6d0881ee-9d49-43c2-96c6-2f7b196bcb40\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler is RandomSampler\n",
      "Sampler is CmaEsSampler\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())\n",
    "print(f\"Sampler is {study.sampler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Algorithms\n",
    "\n",
    "``Pruners`` automatically stop unpromising trials at the early stages of the training (a.k.a., automated early-stopping).\n",
    "\n",
    "Optuna provides the following pruning algorithms:\n",
    "\n",
    "- Asynchronous Successive Halving algorithm implemented in :class:`optuna.pruners.SuccessiveHalvingPruner`\n",
    "\n",
    "- Hyperband algorithm implemented in :class:`optuna.pruners.HyperbandPruner`\n",
    "\n",
    "- Median pruning algorithm implemented in :class:`optuna.pruners.MedianPruner`\n",
    "\n",
    "- Threshold pruning algorithm implemented in :class:`optuna.pruners.ThresholdPruner`\n",
    "\n",
    "We use :class:`optuna.pruners.MedianPruner` in most examples,\n",
    "though basically it is outperformed by :class:`optuna.pruners.SuccessiveHalvingPruner` and\n",
    ":class:`optuna.pruners.HyperbandPruner` as in `this benchmark result <https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako>`_.\n",
    "\n",
    "\n",
    "## Activating Pruners\n",
    "To turn on the pruning feature, you need to call :func:`~optuna.trial.Trial.report` and :func:`~optuna.trial.Trial.should_prune` after each step of the iterative training.\n",
    ":func:`~optuna.trial.Trial.report` periodically monitors the intermediate objective values.\n",
    ":func:`~optuna.trial.Trial.should_prune` decides termination of the trial that does not meet a predefined condition.\n",
    "\n",
    "We would recommend using integration modules for major machine learning frameworks.\n",
    "Exclusive list is :mod:`optuna.integration` and usecases are available in  `optuna/examples <https://github.com/optuna/optuna-examples/>`_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "    classes = list(set(iris.target))\n",
    "    train_x, valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(\n",
    "        iris.data, iris.target, test_size=0.25, random_state=0\n",
    "    )\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-5, 1e-1, log=True)\n",
    "    clf = sklearn.linear_model.SGDClassifier(alpha=alpha)\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(train_x, train_y, classes=classes)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        intermediate_value = 1.0 - clf.score(valid_x, valid_y)\n",
    "        trial.report(intermediate_value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return 1.0 - clf.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the median stopping rule as the pruning condition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:22,687]\u001b[0m A new study created in memory with name: no-name-df9f15af-9d7b-4c3c-945d-1dee8cdbffd4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: no-name-df9f15af-9d7b-4c3c-945d-1dee8cdbffd4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:22,911]\u001b[0m Trial 0 finished with value: 0.3421052631578947 and parameters: {'alpha': 0.060841530961298955}. Best is trial 0 with value: 0.3421052631578947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.3421052631578947 and parameters: {'alpha': 0.060841530961298955}. Best is trial 0 with value: 0.3421052631578947.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,134]\u001b[0m Trial 1 finished with value: 0.3157894736842105 and parameters: {'alpha': 0.0003216699606419239}. Best is trial 1 with value: 0.3157894736842105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.3157894736842105 and parameters: {'alpha': 0.0003216699606419239}. Best is trial 1 with value: 0.3157894736842105.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,343]\u001b[0m Trial 2 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.010069351637247382}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.010069351637247382}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,558]\u001b[0m Trial 3 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.0011535609639430648}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.0011535609639430648}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,791]\u001b[0m Trial 4 finished with value: 0.13157894736842102 and parameters: {'alpha': 0.0002659036458399574}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.13157894736842102 and parameters: {'alpha': 0.0002659036458399574}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,799]\u001b[0m Trial 5 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:23,809]\u001b[0m Trial 6 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,069]\u001b[0m Trial 7 finished with value: 0.07894736842105265 and parameters: {'alpha': 8.812771358101007e-05}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 0.07894736842105265 and parameters: {'alpha': 8.812771358101007e-05}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,078]\u001b[0m Trial 8 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,089]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,378]\u001b[0m Trial 10 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.011701855917947581}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.011701855917947581}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,391]\u001b[0m Trial 11 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,404]\u001b[0m Trial 12 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,421]\u001b[0m Trial 13 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,673]\u001b[0m Trial 14 finished with value: 0.1842105263157895 and parameters: {'alpha': 0.026261855176407917}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 finished with value: 0.1842105263157895 and parameters: {'alpha': 0.026261855176407917}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,951]\u001b[0m Trial 15 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.0024577458725525054}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 finished with value: 0.02631578947368418 and parameters: {'alpha': 0.0024577458725525054}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,964]\u001b[0m Trial 16 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:24,979]\u001b[0m Trial 17 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:25,265]\u001b[0m Trial 18 finished with value: 0.26315789473684215 and parameters: {'alpha': 0.0003575813036902324}. Best is trial 2 with value: 0.02631578947368418.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 finished with value: 0.26315789473684215 and parameters: {'alpha': 0.0003575813036902324}. Best is trial 2 with value: 0.02631578947368418.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-05 22:59:25,276]\u001b[0m Trial 19 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 pruned. \n"
     ]
    }
   ],
   "source": [
    "# Add stream handler of stdout to show the messages\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, several trials were pruned (stopped) before they finished all of the iterations.\n",
    "The format of message is ``\"Trial <Trial Number> pruned.\"``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Sampler and Pruner Should be Used?\n",
    "\n",
    "From the benchmark results which are available at `optuna/optuna - wiki \"Benchmarks with Kurobako\" <https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako>`_, at least for not deep learning tasks, we would say that\n",
    "\n",
    "* For :class:`optuna.samplers.RandomSampler`, :class:`optuna.pruners.MedianPruner` is the best.\n",
    "* For :class:`optuna.samplers.TPESampler`, :class:`optuna.pruners.Hyperband` is the best.\n",
    "\n",
    "However, note that the benchmark is not deep learning.\n",
    "For deep learning tasks,\n",
    "consult the below table.\n",
    "This table is from the `Ozaki et al., Hyperparameter Optimization Methods: Overview and Characteristics, in IEICE Trans, Vol.J103-D No.9 pp.615-631, 2020 <https://doi.org/10.14923/transinfj.2019JDR0003>`_ paper,\n",
    "which is written in Japanese.\n",
    "\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n",
    "| Parallel Compute Resource | Categorical/Conditional Hyperparameters | Recommended Algorithms                                        |\n",
    "+===========================+=========================================+===============================================================+\n",
    "| Limited                   | No                                      | TPE. GP-EI if search space is low-dimensional and continuous. |\n",
    "+                           +-----------------------------------------+---------------------------------------------------------------+\n",
    "|                           | Yes                                     | TPE. GP-EI if search space is low-dimensional and continuous  |\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n",
    "| Sufficient                | No                                      | CMA-ES, Random Search                                         |\n",
    "+                           +-----------------------------------------+---------------------------------------------------------------+\n",
    "|                           | Yes                                     | Random Search or Genetic Algorithm                            |\n",
    "+---------------------------+-----------------------------------------+---------------------------------------------------------------+\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Modules for Pruning\n",
    "To implement pruning mechanism in much simpler forms, Optuna provides integration modules for the following libraries.\n",
    "\n",
    "For the complete list of Optuna's integration modules, see :mod:`optuna.integration`.\n",
    "\n",
    "For example, :class:`~optuna.integration.XGBoostPruningCallback` introduces pruning without directly changing the logic of training iteration.\n",
    "(See also `example <https://github.com/optuna/optuna-examples/tree/main/xgboost/xgboost_integration.py>`_ for the entire script.)\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "        pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-error')\n",
    "        bst = xgb.train(param, dtrain, evals=[(dvalid, 'validation')], callbacks=[pruning_callback])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
